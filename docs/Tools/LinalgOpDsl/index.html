<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>linalg_opdsl tool - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Tools/LinalgOpDsl/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>linalg_opdsl tool</h1><p>Python based DSL for authoring Linalg op definitions and generating
<code>linalg.generic</code> IR based on them for samples.</p><p>The tool <code>linalg_opdsl</code> provides a high level DSL for constructing
structured op definitions in a way that can be exported to built-in, named
structured ops via the above YAML-based definitions or used interactively to
emit corresponding <code>linalg.generic</code> IR for the composition.</p><h2 id=basic-usage>Basic usage&nbsp;<a class=headline-hash href=#basic-usage>¶</a></h2><p>The tool is bundled with the MLIR Python bindings. To use from the CMake build
tree, MLIR must be build with Python bindings enabled
(<code>-DMLIR_BINDINGS_PYTHON_ENABLED=ON</code>). Then add the <code>python</code> directory in the
build tree to your <code>PYTHONPATH</code> environment variable (i.e.
<code>export PYTHONPATH=$PWD/build/python</code>). Optionally, use an installed MLIR
package, if available, to avoid building.</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># Dump the `core_named_ops.py` module as YAML.</span>
python -m python -m mlir.tools.linalg_opdsl.dump_oplib .ops.core_named_ops
</code></pre></div><p>The tool is meant for use during both development and runtime, but not as
a build tool of the core compiler: in order to export static named op
definitions to be built as part of the compiler, the corresponding Linalg
dialect YAML file must be updated and reviewed. TODO: Develop a script to
automate op updates to these files.</p><h2 id=language-guide>Language Guide&nbsp;<a class=headline-hash href=#language-guide>¶</a></h2><p>The language presented here is loosely inspired from the
<a href=https://arxiv.org/pdf/1802.04730.pdf>Tensor Comprehensions</a>
work, adapted to
represent linalg structured ops.</p><p>This tool is new and rapidly evolving. For language examples, refer to the
built-in ops in the <code>mlir.tools.linalg_opdsl.ops</code> package
(<code>lib/Bindings/Python/mlir/tools/linalg_opdsl/ops</code> in the repository).</p><p>Using a matmul as an example, we will decompose the language:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>T1</span> <span class=o>=</span> <span class=n>TV</span><span class=o>.</span><span class=n>T1</span>
<span class=n>T2</span> <span class=o>=</span> <span class=n>TV</span><span class=o>.</span><span class=n>T2</span>

<span class=nd>@linalg_structured_op</span>
<span class=k>def</span> <span class=nf>matmul</span><span class=p>(</span><span class=n>A</span><span class=o>=</span><span class=n>TensorDef</span><span class=p>(</span><span class=n>T1</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>M</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>K</span><span class=p>),</span>
           <span class=n>B</span><span class=o>=</span><span class=n>TensorDef</span><span class=p>(</span><span class=n>T2</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>K</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>N</span><span class=p>),</span>
           <span class=n>C</span><span class=o>=</span><span class=n>TensorDef</span><span class=p>(</span><span class=n>U</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>M</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>N</span><span class=p>,</span> <span class=n>output</span><span class=o>=</span><span class=bp>True</span><span class=p>)):</span>
  <span class=s2>&#34;&#34;&#34;Performs a matrix multiplication of two 2D inputs.
</span><span class=s2>
</span><span class=s2>  Numeric casting is performed on the operands to the inner multiply, promoting
</span><span class=s2>  them to the same data type as the accumulator/output.
</span><span class=s2>  &#34;&#34;&#34;</span>
  <span class=n>implements</span><span class=p>(</span><span class=n>ContractionOpInterface</span><span class=p>)</span>
  <span class=n>C</span><span class=p>[</span><span class=n>D</span><span class=o>.</span><span class=n>m</span><span class=p>,</span> <span class=n>D</span><span class=o>.</span><span class=n>n</span><span class=p>]</span> <span class=o>+=</span> <span class=n>cast</span><span class=p>(</span><span class=n>U</span><span class=p>,</span> <span class=n>A</span><span class=p>[</span><span class=n>D</span><span class=o>.</span><span class=n>m</span><span class=p>,</span> <span class=n>D</span><span class=o>.</span><span class=n>k</span><span class=p>])</span> <span class=o>*</span> <span class=n>cast</span><span class=p>(</span><span class=n>U</span><span class=p>,</span> <span class=n>B</span><span class=p>[</span><span class=n>D</span><span class=o>.</span><span class=n>k</span><span class=p>,</span> <span class=n>D</span><span class=o>.</span><span class=n>n</span><span class=p>])</span>
</code></pre></div><p>Here we have a simple type polymorphic contraction that takes arguments <code>A</code>
and <code>B</code> and outputs <code>C</code>. Each is bound to a <code>TensorDef</code>, which specifies:</p><ul><li>The symbolic element type (<code>T1</code>, <code>T2</code>, <code>U</code> above).</li><li>Symbolic shape expressions with symbols that are bound globally for the op (
note that in this simple example, the shape expressions are just symbol
references, but they are permitted to be a constrained set of affine
expressions).</li><li>Usage (<code>output=True</code>).</li></ul><p>The docstring will be transferred to the op definition verbatim.</p><p>Special identifying op interfaces can be declared for the op via
<code>implements(interface1[, interface2...])</code>.</p><h2 id=parameters>Parameters&nbsp;<a class=headline-hash href=#parameters>¶</a></h2><p>Structured operations can take two types of parameters namely input/output
tensors and captures. Assignment expressions index the tensor parameters to
access the individual elements, while captures are scalars that can be
accessed directly.</p><p>The following example demonstrates the use of the two parameter types:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=nd>@linalg_structured_op</span>
<span class=k>def</span> <span class=nf>copy_and_scale</span><span class=p>(</span><span class=n>I</span><span class=o>=</span><span class=n>TensorDef</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>M</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>K</span><span class=p>),</span>
                   <span class=n>O</span><span class=o>=</span><span class=n>TensorDef</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>M</span><span class=p>,</span> <span class=n>S</span><span class=o>.</span><span class=n>K</span><span class=p>,</span> <span class=n>output</span><span class=o>=</span><span class=bp>True</span><span class=p>),</span>
                   <span class=n>val</span><span class=o>=</span><span class=n>CaptureDef</span><span class=p>(</span><span class=n>T</span><span class=p>)):</span>
  <span class=s2>&#34;&#34;&#34;Scale the input by the captured value and store the result&#34;&#34;&#34;</span>
  <span class=n>O</span><span class=p>[</span><span class=n>D</span><span class=o>.</span><span class=n>m</span><span class=p>,</span> <span class=n>D</span><span class=o>.</span><span class=n>n</span><span class=p>]</span> <span class=o>=</span> <span class=n>I</span><span class=p>[</span><span class=n>D</span><span class=o>.</span><span class=n>m</span><span class=p>,</span> <span class=n>D</span><span class=o>.</span><span class=n>n</span><span class=p>]</span> <span class=o>*</span> <span class=n>val</span>
</code></pre></div><p>The operation scales the input tensor <code>I</code> scales its elements by the value
<code>val</code> and writes the result to the output tensor <code>out</code>. The capture <code>val</code> is
bound to a <code>CaptureDef</code>, which specifies the type of the captured value. The
tensors are bound to a <code>TensorDef</code> as demonstrated by the matmul example. All
parameters appear in the parameter list of the operation:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>fill</span><span class=p>(</span><span class=n>in_tensor</span><span class=p>,</span> <span class=n>outs</span><span class=o>=</span><span class=p>[</span><span class=n>out_tensor</span><span class=p>],</span> <span class=n>captures</span><span class=o>=</span><span class=p>[</span><span class=n>captured_val</span><span class=p>])</span>
</code></pre></div><h2 id=assignments>Assignments&nbsp;<a class=headline-hash href=#assignments>¶</a></h2><p>The bulk of language consists of assignment expressions of the form above.
The iteration dimension order is determined lexically based on the order
encountered in the expression (following operator precedence if math operators
are used). TODO: Introduce a directive to fix the dimension bindings.</p><p>Reduction dimensions are inferred to be any dimensions on the RHS that are not
on the LHS.</p><p>A number of arithmetic primitive functions are supported:</p><ul><li><code>PrimFn.add(a, b)</code> (also via overloading the binary <code>+</code> operator)</li><li><code>PrimFn.exp(a)</code></li><li><code>PrimFn.log(a)</code></li><li><code>PrimFn.mul(a, b)</code> (also via overloading the binary <code>*</code> operator)</li><li><code>PrimFn.max(a, b)</code></li><li><code>PrimFn.sub(a, b)</code> (also via overloading the binary <code>-</code> operator)</li></ul><p>Reduction functions can appear as the outer-most function on the RHS:</p><ul><li><code>ReduceFn.add</code> (also overloading the inplace <code>+=</code> on a LHS)</li><li><code>ReduceFn.mul</code></li><li><code>ReduceFn.max</code></li></ul><p>There are also special forms:</p><ul><li><code>cast(TypeVar, operand)</code> casts the <code>operand</code> to the target type <code>TypeVar</code>.</li><li><code>const(TypeVar, value)</code> returns a constant value of type <code>TypeVar</code>.</li><li><code>index(dim)</code> returns the iteration index in the given dimension <code>dim</code>.</li></ul><h2 id=types>Types&nbsp;<a class=headline-hash href=#types>¶</a></h2><p>All types in assignment expressions are late bound based on actual input
and output types of constructed ops. An exception are predefined types such as
<code>I32</code>, <code>I64</code>, <code>F32</code>, and <code>F64</code>. These hardwired types enable intermediate
computations with a type that is independent of the input and output types.
For example, parts of floating point computation may require double precision
arithmetic despite all inputs and outputs being single precision values.
Assignment expressions with no <code>cast</code> calls will generally require uniform
types throughout and will fail to verify if violated. The presence of a
<code>cast</code> allows for a limited form of numeric type conversion between element
types that can be derived from inputs and outputs (and in the future,
attributes). <code>cast</code> calls with a <code>TypeVar</code> first argument are emitted as
<code>symbolic_cast</code> primitives in the YAML definition.</p><p>Casting will perform <code>int&lt;->float</code> and <code>index->int</code> type conversions and will
perform any necessary extension or truncation within type family. Note that
presently, any integer type is assumed to be signed for the purpose of
determining how to extend or truncate. Supporting unsigned integer types is
left for future work.</p><p>Not all functions are applicable for all numeric types, and on mismatch, op
verification will fail.</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Tools/ title=Tools><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Tools</a>
<a class="nav nav-next" href=/docs/Tools/MLIRLSP/ title="MLIR : Language Server Protocol">Next - MLIR : Language Server Protocol <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/Tools/>Tools<span class="mark opened">-</span></a><ul class=sub-menu><li class=active><a href=/docs/Tools/LinalgOpDsl/>linalg_opdsl tool</a></li><li><a href=/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li></ul></li><li><a href=/docs/MemRefPasses/></a></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=/docs/Bufferization/>Bufferization</a></li><li><a href=/docs/LLVMDialectMemRefConvention/>Built-in Function and MemRef Calling Convention</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/DataLayout/>Data Layout Modeling</a></li><li><a href=/docs/DebugActions/>Debug Actions</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/DLTIDialect/></a></li><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=/docs/Dialects/Linalg/>'linalg' Dialect</a></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/Standard/>'std' Dialect</a></li><li><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li></ul></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/DefiningAttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>