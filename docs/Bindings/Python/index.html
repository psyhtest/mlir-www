<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>MLIR Python Bindings - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.80.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Bindings/Python/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>MLIR Python Bindings</h1><p>Current status: Under development and not enabled by default</p><h2 id=building>Building&nbsp;<a class=headline-hash href=#building>¶</a></h2><h3 id=pre-requisites>Pre-requisites&nbsp;<a class=headline-hash href=#pre-requisites>¶</a></h3><ul><li>A relatively recent Python3 installation</li><li>Installation of python dependencies as specified in
<code>mlir/lib/Bindings/Python/requirements.txt</code></li></ul><h3 id=cmake-variables>CMake variables&nbsp;<a class=headline-hash href=#cmake-variables>¶</a></h3><ul><li><p><strong><code>MLIR_BINDINGS_PYTHON_ENABLED</code></strong><code>:BOOL</code></p><p>Enables building the Python bindings. Defaults to <code>OFF</code>.</p></li><li><p><strong><code>Python3_EXECUTABLE</code></strong>:<code>STRING</code></p><p>Specifies the <code>python</code> executable used for the LLVM build, including for
determining header/link flags for the Python bindings. On systems with
multiple Python implementations, setting this explicitly to the preferred
<code>python3</code> executable is strongly recommended.</p></li><li><p><strong><code>MLIR_PYTHON_BINDINGS_VERSION_LOCKED</code></strong><code>:BOOL</code></p><p>Links the native extension against the Python runtime library, which is
optional on some platforms. While setting this to <code>OFF</code> can yield some greater
deployment flexibility, linking in this way allows the linker to report
compile time errors for unresolved symbols on all platforms, which makes for a
smoother development workflow. Defaults to <code>ON</code>.</p></li></ul><h3 id=recommended-development-practices>Recommended development practices&nbsp;<a class=headline-hash href=#recommended-development-practices>¶</a></h3><p>It is recommended to use a python virtual environment. Many ways exist for this,
but the following is the simplest:</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell><span class=c1># Make sure your &#39;python&#39; is what you expect. Note that on multi-python</span>
<span class=c1># systems, this may have a version suffix, and on many Linuxes and MacOS where</span>
<span class=c1># python2 and python3 co-exist, you may also want to use `python3`.</span>
which python
python -m venv ~/.venv/mlirdev
<span class=nb>source</span> ~/.venv/mlirdev/bin/activate

<span class=c1># Note that many LTS distros will bundle a version of pip itself that is too</span>
<span class=c1># old to download all of the latest binaries for certain platforms.</span>
<span class=c1># The pip version can be obtained with `python -m pip --version`, and for</span>
<span class=c1># Linux specifically, this should be cross checked with minimum versions</span>
<span class=c1># here: https://github.com/pypa/manylinux</span>
<span class=c1># It is recommended to upgrade pip:</span>
python -m pip install --upgrade pip


<span class=c1># Now the `python` command will resolve to your virtual environment and</span>
<span class=c1># packages will be installed there.</span>
python -m pip install -r mlir/lib/Bindings/Python/requirements.txt

<span class=c1># Now run `cmake`, `ninja`, et al.</span>
</code></pre></div><p>For interactive use, it is sufficient to add the <code>python</code> directory in your
<code>build/</code> directory to the <code>PYTHONPATH</code>. Typically:</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell><span class=nb>export</span> <span class=nv>PYTHONPATH</span><span class=o>=</span><span class=k>$(</span><span class=nb>cd</span> build <span class=o>&amp;&amp;</span> <span class=nb>pwd</span><span class=k>)</span>/python
</code></pre></div><h2 id=design>Design&nbsp;<a class=headline-hash href=#design>¶</a></h2><h3 id=use-cases>Use cases&nbsp;<a class=headline-hash href=#use-cases>¶</a></h3><p>There are likely two primary use cases for the MLIR python bindings:</p><ol><li><p>Support users who expect that an installed version of LLVM/MLIR will yield
the ability to <code>import mlir</code> and use the API in a pure way out of the box.</p></li><li><p>Downstream integrations will likely want to include parts of the API in their
private namespace or specially built libraries, probably mixing it with other
python native bits.</p></li></ol><h3 id=composable-modules>Composable modules&nbsp;<a class=headline-hash href=#composable-modules>¶</a></h3><p>In order to support use case #2, the Python bindings are organized into
composable modules that downstream integrators can include and re-export into
their own namespace if desired. This forces several design points:</p><ul><li><p>Separate the construction/populating of a <code>py::module</code> from <code>PYBIND11_MODULE</code>
global constructor.</p></li><li><p>Introduce headers for C++-only wrapper classes as other related C++ modules
will need to interop with it.</p></li><li><p>Separate any initialization routines that depend on optional components into
its own module/dependency (currently, things like <code>registerAllDialects</code> fall
into this category).</p></li></ul><p>There are a lot of co-related issues of shared library linkage, distribution
concerns, etc that affect such things. Organizing the code into composable
modules (versus a monolithic <code>cpp</code> file) allows the flexibility to address many
of these as needed over time. Also, compilation time for all of the template
meta-programming in pybind scales with the number of things you define in a
translation unit. Breaking into multiple translation units can significantly aid
compile times for APIs with a large surface area.</p><h3 id=submodules>Submodules&nbsp;<a class=headline-hash href=#submodules>¶</a></h3><p>Generally, the C++ codebase namespaces most things into the <code>mlir</code> namespace.
However, in order to modularize and make the Python bindings easier to
understand, sub-packages are defined that map roughly to the directory structure
of functional units in MLIR.</p><p>Examples:</p><ul><li><code>mlir.ir</code></li><li><code>mlir.passes</code> (<code>pass</code> is a reserved word :( )</li><li><code>mlir.dialect</code></li><li><code>mlir.execution_engine</code> (aside from namespacing, it is important that
&ldquo;bulky&rdquo;/optional parts like this are isolated)</li></ul><p>In addition, initialization functions that imply optional dependencies should
be in underscored (notionally private) modules such as <code>_init</code> and linked
separately. This allows downstream integrators to completely customize what is
included &ldquo;in the box&rdquo; and covers things like dialect registration,
pass registration, etc.</p><h3 id=loader>Loader&nbsp;<a class=headline-hash href=#loader>¶</a></h3><p>LLVM/MLIR is a non-trivial python-native project that is likely to co-exist with
other non-trivial native extensions. As such, the native extension (i.e. the
<code>.so</code>/<code>.pyd</code>/<code>.dylib</code>) is exported as a notionally private top-level symbol
(<code>_mlir</code>), while a small set of Python code is provided in
<code>mlir/_cext_loader.py</code> and siblings which loads and re-exports it. This
split provides a place to stage code that needs to prepare the environment
<em>before</em> the shared library is loaded into the Python runtime, and also
provides a place that one-time initialization code can be invoked apart from
module constructors.</p><p>It is recommended to avoid using <code>__init__.py</code> files to the extent possible,
until reaching a leaf package that represents a discrete component. The rule
to keep in mind is that the presence of an <code>__init__.py</code> file prevents the
ability to split anything at that level or below in the namespace into
different directories, deployment packages, wheels, etc.</p><p>See the documentation for more information and advice:
<a href=https://packaging.python.org/guides/packaging-namespace-packages/>https://packaging.python.org/guides/packaging-namespace-packages/</a></p><h3 id=use-the-c-api>Use the C-API&nbsp;<a class=headline-hash href=#use-the-c-api>¶</a></h3><p>The Python APIs should seek to layer on top of the C-API to the degree possible.
Especially for the core, dialect-independent parts, such a binding enables
packaging decisions that would be difficult or impossible if spanning a C++ ABI
boundary. In addition, factoring in this way side-steps some very difficult
issues that arise when combining RTTI-based modules (which pybind derived things
are) with non-RTTI polymorphic C++ code (the default compilation mode of LLVM).</p><h3 id=ownership-in-the-core-ir>Ownership in the Core IR&nbsp;<a class=headline-hash href=#ownership-in-the-core-ir>¶</a></h3><p>There are several top-level types in the core IR that are strongly owned by their python-side reference:</p><ul><li><code>PyContext</code> (<code>mlir.ir.Context</code>)</li><li><code>PyModule</code> (<code>mlir.ir.Module</code>)</li><li><code>PyOperation</code> (<code>mlir.ir.Operation</code>) - but with caveats</li></ul><p>All other objects are dependent. All objects maintain a back-reference
(keep-alive) to their closest containing top-level object. Further, dependent
objects fall into two categories: a) uniqued (which live for the life-time of
the context) and b) mutable. Mutable objects need additional machinery for
keeping track of when the C++ instance that backs their Python object is no
longer valid (typically due to some specific mutation of the IR, deletion, or
bulk operation).</p><h3 id=optionality-and-argument-ordering-in-the-core-ir>Optionality and argument ordering in the Core IR&nbsp;<a class=headline-hash href=#optionality-and-argument-ordering-in-the-core-ir>¶</a></h3><p>The following types support being bound to the current thread as a context manager:</p><ul><li><code>PyLocation</code> (<code>loc: mlir.ir.Location = None</code>)</li><li><code>PyInsertionPoint</code> (<code>ip: mlir.ir.InsertionPoint = None</code>)</li><li><code>PyMlirContext</code> (<code>context: mlir.ir.Context = None</code>)</li></ul><p>In order to support composability of function arguments, when these types appear
as arguments, they should always be the last and appear in the above order and
with the given names (which is generally the order in which they are expected to
need to be expressed explicitly in special cases) as necessary. Each should
carry a default value of <code>py::none()</code> and use either a manual or automatic
conversion for resolving either with the explicit value or a value from the
thread context manager (i.e. <code>DefaultingPyMlirContext</code> or
<code>DefaultingPyLocation</code>).</p><p>The rationale for this is that in Python, trailing keyword arguments to the
<em>right</em> are the most composable, enabling a variety of strategies such as kwarg
passthrough, default values, etc. Keeping function signatures composable
increases the chances that interesting DSLs and higher level APIs can be
constructed without a lot of exotic boilerplate.</p><p>Used consistently, this enables a style of IR construction that rarely needs to
use explicit contexts, locations, or insertion points but is free to do so when
extra control is needed.</p><h4 id=operation-hierarchy>Operation hierarchy&nbsp;<a class=headline-hash href=#operation-hierarchy>¶</a></h4><p>As mentioned above, <code>PyOperation</code> is special because it can exist in either a
top-level or dependent state. The life-cycle is unidirectional: operations can
be created detached (top-level) and once added to another operation, they are
then dependent for the remainder of their lifetime. The situation is more
complicated when considering construction scenarios where an operation is added
to a transitive parent that is still detached, necessitating further accounting
at such transition points (i.e. all such added children are initially added to
the IR with a parent of their outer-most detached operation, but then once it is
added to an attached operation, they need to be re-parented to the containing
module).</p><p>Due to the validity and parenting accounting needs, <code>PyOperation</code> is the owner
for regions and blocks and needs to be a top-level type that we can count on not
aliasing. This let&rsquo;s us do things like selectively invalidating instances when
mutations occur without worrying that there is some alias to the same operation
in the hierarchy. Operations are also the only entity that are allowed to be in
a detached state, and they are interned at the context level so that there is
never more than one Python <code>mlir.ir.Operation</code> object for a unique
<code>MlirOperation</code>, regardless of how it is obtained.</p><p>The C/C++ API allows for Region/Block to also be detached, but it simplifies the
ownership model a lot to eliminate that possibility in this API, allowing the
Region/Block to be completely dependent on its owning operation for accounting.
The aliasing of Python <code>Region</code>/<code>Block</code> instances to underlying
<code>MlirRegion</code>/<code>MlirBlock</code> is considered benign and these objects are not interned
in the context (unlike operations).</p><p>If we ever want to re-introduce detached regions/blocks, we could do so with new
&ldquo;DetachedRegion&rdquo; class or similar and also avoid the complexity of accounting.
With the way it is now, we can avoid having a global live list for regions and
blocks. We may end up needing an op-local one at some point TBD, depending on
how hard it is to guarantee how mutations interact with their Python peer
objects. We can cross that bridge easily when we get there.</p><p>Module, when used purely from the Python API, can&rsquo;t alias anyway, so we can use
it as a top-level ref type without a live-list for interning. If the API ever
changes such that this cannot be guaranteed (i.e. by letting you marshal a
native-defined Module in), then there would need to be a live table for it too.</p><h2 id=style>Style&nbsp;<a class=headline-hash href=#style>¶</a></h2><p>In general, for the core parts of MLIR, the Python bindings should be largely
isomorphic with the underlying C++ structures. However, concessions are made
either for practicality or to give the resulting library an appropriately
&ldquo;Pythonic&rdquo; flavor.</p><h3 id=properties-vs-get-methods>Properties vs get*() methods&nbsp;<a class=headline-hash href=#properties-vs-get-methods>¶</a></h3><p>Generally favor converting trivial methods like <code>getContext()</code>, <code>getName()</code>,
<code>isEntryBlock()</code>, etc to read-only Python properties (i.e. <code>context</code>). It is
primarily a matter of calling <code>def_property_readonly</code> vs <code>def</code> in binding code,
and makes things feel much nicer to the Python side.</p><p>For example, prefer:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=n>m</span><span class=p>.</span><span class=n>def_property_readonly</span><span class=p>(</span><span class=s>&#34;context&#34;</span><span class=p>,</span> <span class=p>...)</span>
</code></pre></div><p>Over:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=n>m</span><span class=p>.</span><span class=n>def</span><span class=p>(</span><span class=s>&#34;getContext&#34;</span><span class=p>,</span> <span class=p>...)</span>
</code></pre></div><h3 id=__repr__-methods><strong>repr</strong> methods&nbsp;<a class=headline-hash href=#__repr__-methods>¶</a></h3><p>Things that have nice printed representations are really great :) If there is a
reasonable printed form, it can be a significant productivity boost to wire that
to the <code>__repr__</code> method (and verify it with a
<a href=#sample-doctest>doctest</a>
).</p><h3 id=camelcase-vs-snake_case>CamelCase vs snake_case&nbsp;<a class=headline-hash href=#camelcase-vs-snake_case>¶</a></h3><p>Name functions/methods/properties in <code>snake_case</code> and classes in <code>CamelCase</code>. As
a mechanical concession to Python style, this can go a long way to making the
API feel like it fits in with its peers in the Python landscape.</p><p>If in doubt, choose names that will flow properly with other
<a href=https://pep8.org/#descriptive-naming-styles>PEP 8 style names</a>
.</p><h3 id=prefer-pseudo-containers>Prefer pseudo-containers&nbsp;<a class=headline-hash href=#prefer-pseudo-containers>¶</a></h3><p>Many core IR constructs provide methods directly on the instance to query count
and begin/end iterators. Prefer hoisting these to dedicated pseudo containers.</p><p>For example, a direct mapping of blocks within regions could be done this way:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>region</span> <span class=o>=</span> <span class=o>...</span>

<span class=k>for</span> <span class=n>block</span> <span class=ow>in</span> <span class=n>region</span><span class=p>:</span>

  <span class=k>pass</span>
</code></pre></div><p>However, this way is preferred:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>region</span> <span class=o>=</span> <span class=o>...</span>

<span class=k>for</span> <span class=n>block</span> <span class=ow>in</span> <span class=n>region</span><span class=o>.</span><span class=n>blocks</span><span class=p>:</span>

  <span class=k>pass</span>

<span class=k>print</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>region</span><span class=o>.</span><span class=n>blocks</span><span class=p>))</span>
<span class=k>print</span><span class=p>(</span><span class=n>region</span><span class=o>.</span><span class=n>blocks</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=k>print</span><span class=p>(</span><span class=n>region</span><span class=o>.</span><span class=n>blocks</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</code></pre></div><p>Instead of leaking STL-derived identifiers (<code>front</code>, <code>back</code>, etc), translate
them to appropriate <code>__dunder__</code> methods and iterator wrappers in the bindings.</p><p>Note that this can be taken too far, so use good judgment. For example, block
arguments may appear container-like but have defined methods for lookup and
mutation that would be hard to model properly without making semantics
complicated. If running into these, just mirror the C/C++ API.</p><h3 id=provide-one-stop-helpers-for-common-things>Provide one stop helpers for common things&nbsp;<a class=headline-hash href=#provide-one-stop-helpers-for-common-things>¶</a></h3><p>One stop helpers that aggregate over multiple low level entities can be
incredibly helpful and are encouraged within reason. For example, making
<code>Context</code> have a <code>parse_asm</code> or equivalent that avoids needing to explicitly
construct a SourceMgr can be quite nice. One stop helpers do not have to be
mutually exclusive with a more complete mapping of the backing constructs.</p><h2 id=testing>Testing&nbsp;<a class=headline-hash href=#testing>¶</a></h2><p>Tests should be added in the <code>test/Bindings/Python</code> directory and should
typically be <code>.py</code> files that have a lit run line.</p><p>We use <code>lit</code> and <code>FileCheck</code> based tests:</p><ul><li>For generative tests (those that produce IR), define a Python module that
constructs/prints the IR and pipe it through <code>FileCheck</code>.</li><li>Parsing should be kept self-contained within the module under test by use of
raw constants and an appropriate <code>parse_asm</code> call.</li><li>Any file I/O code should be staged through a tempfile vs relying on file
artifacts/paths outside of the test module.</li><li>For convenience, we also test non-generative API interactions with the same
mechanisms, printing and <code>CHECK</code>ing as needed.</li></ul><h3 id=sample-filecheck-test>Sample FileCheck test&nbsp;<a class=headline-hash href=#sample-filecheck-test>¶</a></h3><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1># RUN: %PYTHON %s | mlir-opt -split-input-file | FileCheck</span>

<span class=c1># TODO: Move to a test utility class once any of this actually exists.</span>
<span class=k>def</span> <span class=nf>print_module</span><span class=p>(</span><span class=n>f</span><span class=p>):</span>
  <span class=n>m</span> <span class=o>=</span> <span class=n>f</span><span class=p>()</span>
  <span class=k>print</span><span class=p>(</span><span class=s2>&#34;// -----&#34;</span><span class=p>)</span>
  <span class=k>print</span><span class=p>(</span><span class=s2>&#34;// TEST_FUNCTION:&#34;</span><span class=p>,</span> <span class=n>f</span><span class=o>.</span><span class=vm>__name__</span><span class=p>)</span>
  <span class=k>print</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>to_asm</span><span class=p>())</span>
  <span class=k>return</span> <span class=n>f</span>

<span class=c1># CHECK-LABEL: TEST_FUNCTION: create_my_op</span>
<span class=nd>@print_module</span>
<span class=k>def</span> <span class=nf>create_my_op</span><span class=p>():</span>
  <span class=n>m</span> <span class=o>=</span> <span class=n>mlir</span><span class=o>.</span><span class=n>ir</span><span class=o>.</span><span class=n>Module</span><span class=p>()</span>
  <span class=n>builder</span> <span class=o>=</span> <span class=n>m</span><span class=o>.</span><span class=n>new_op_builder</span><span class=p>()</span>
  <span class=c1># CHECK: mydialect.my_operation ...</span>
  <span class=n>builder</span><span class=o>.</span><span class=n>my_op</span><span class=p>()</span>
  <span class=k>return</span> <span class=n>m</span>
</code></pre></div><h2 id=integration-with-ods>Integration with ODS&nbsp;<a class=headline-hash href=#integration-with-ods>¶</a></h2><p>The MLIR Python bindings integrate with the tablegen-based ODS system for
providing user-friendly wrappers around MLIR dialects and operations. There
are multiple parts to this integration, outlined below. Most details have
been elided: refer to the build rules and python sources under <code>mlir.dialects</code>
for the canonical way to use this facility.</p><p>Users are responsible for providing a <code>{DIALECT_NAMESPACE}.py</code> (or an
equivalent directory with <code>__init__.py</code> file) as the entrypoint.</p><h3 id=generating-_dialect_namespace_ops_genpy-wrapper-modules>Generating <code>_{DIALECT_NAMESPACE}_ops_gen.py</code> wrapper modules&nbsp;<a class=headline-hash href=#generating-_dialect_namespace_ops_genpy-wrapper-modules>¶</a></h3><p>Each dialect with a mapping to python requires that an appropriate
<code>_{DIALECT_NAMESPACE}_ops_gen.py</code> wrapper module is created. This is done by
invoking <code>mlir-tblgen</code> on a python-bindings specific tablegen wrapper that
includes the boilerplate and actual dialect specific <code>td</code> file. An example, for
the <code>StandardOps</code> (which is assigned the namespace <code>std</code> as a special case):</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen><span class=cp>#ifndef PYTHON_BINDINGS_STANDARD_OPS</span>
<span class=cp>#define PYTHON_BINDINGS_STANDARD_OPS</span>

<span class=nv>include</span> <span class=s>&#34;mlir/Bindings/Python/Attributes.td&#34;</span>
<span class=nv>include</span> <span class=s>&#34;mlir/Dialect/StandardOps/IR/Ops.td&#34;</span>

<span class=cp>#endif</span>
</code></pre></div><p>In the main repository, building the wrapper is done via the CMake function
<code>add_mlir_dialect_python_bindings</code>, which invokes:</p><pre><code>mlir-tblgen -gen-python-op-bindings -bind-dialect={DIALECT_NAMESPACE} \
    {PYTHON_BINDING_TD_FILE}
</code></pre><p>The generates op classes must be included in the <code>{DIALECT_NAMESPACE}.py</code> file
in a similar way that generated headers are included for C++ generated code:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>from</span> <span class=nn>._my_dialect_ops_gen</span> <span class=kn>import</span> <span class=o>*</span>
</code></pre></div><h3 id=extending-the-search-path-for-wrapper-modules>Extending the search path for wrapper modules&nbsp;<a class=headline-hash href=#extending-the-search-path-for-wrapper-modules>¶</a></h3><p>When the python bindings need to locate a wrapper module, they consult the
<code>dialect_search_path</code> and use it to find an appropriately named module. For
the main repository, this search path is hard-coded to include the
<code>mlir.dialects</code> module, which is where wrappers are emitted by the abobe build
rule. Out of tree dialects and add their modules to the search path by calling:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>mlir</span><span class=o>.</span><span class=n>_cext</span><span class=o>.</span><span class=n>append_dialect_search_prefix</span><span class=p>(</span><span class=s2>&#34;myproject.mlir.dialects&#34;</span><span class=p>)</span>
</code></pre></div><h3 id=wrapper-module-code-organization>Wrapper module code organization&nbsp;<a class=headline-hash href=#wrapper-module-code-organization>¶</a></h3><p>The wrapper module tablegen emitter outputs:</p><ul><li>A <code>_Dialect</code> class (extending <code>mlir.ir.Dialect</code>) with a <code>DIALECT_NAMESPACE</code>
attribute.</li><li>An <code>{OpName}</code> class for each operation (extending <code>mlir.ir.OpView</code>).</li><li>Decorators for each of the above to register with the system.</li></ul><p>Note: In order to avoid naming conflicts, all internal names used by the wrapper
module are prefixed by <code>_ods_</code>.</p><p>Each concrete <code>OpView</code> subclass further defines several public-intended
attributes:</p><ul><li><code>OPERATION_NAME</code> attribute with the <code>str</code> fully qualified operation name
(i.e. <code>std.absf</code>).</li><li>An <code>__init__</code> method for the <em>default builder</em> if one is defined or inferred
for the operation.</li><li><code>@property</code> getter for each operand or result (using an auto-generated name
for unnamed of each).</li><li><code>@property</code> getter, setter and deleter for each declared attribute.</li></ul><p>It further emits additional private-intended attributes meant for subclassing
and customization (default cases omit these attributes in favor of the
defaults on <code>OpView</code>):</p><ul><li><code>_ODS_REGIONS</code>: A specification on the number and types of regions.
Currently a tuple of (min_region_count, has_no_variadic_regions). Note that
the API does some light validation on this but the primary purpose is to
capture sufficient information to perform other default building and region
accessor generation.</li><li><code>_ODS_OPERAND_SEGMENTS</code> and <code>_ODS_RESULT_SEGMENTS</code>: Black-box value which
indicates the structure of either the operand or results with respect to
variadics. Used by <code>OpView._ods_build_default</code> to decode operand and result
lists that contain lists.</li></ul><h4 id=default-builder>Default Builder&nbsp;<a class=headline-hash href=#default-builder>¶</a></h4><p>Presently, only a single, default builder is mapped to the <code>__init__</code> method.
The intent is that this <code>__init__</code> method represents the <em>most specific</em> of
the builders typically generated for C++; however currently it is just the
generic form below.</p><ul><li>One argument for each declared result:<ul><li>For single-valued results: Each will accept an <code>mlir.ir.Type</code>.</li><li>For variadic results: Each will accept a <code>List[mlir.ir.Type]</code>.</li></ul></li><li>One argument for each declared operand or attribute:<ul><li>For single-valued operands: Each will accept an <code>mlir.ir.Value</code>.</li><li>For variadic operands: Each will accept a <code>List[mlir.ir.Value]</code>.</li><li>For attributes, it will accept an <code>mlir.ir.Attribute</code>.</li></ul></li><li>Trailing usage-specific, optional keyword arguments:<ul><li><code>loc</code>: An explicit <code>mlir.ir.Location</code> to use. Defaults to the location
bound to the thread (i.e. <code>with Location.unknown():</code>) or an error if none
is bound nor specified.</li><li><code>ip</code>: An explicit <code>mlir.ir.InsertionPoint</code> to use. Default to the insertion
point bound to the thread (i.e. <code>with InsertionPoint(...):</code>).</li></ul></li></ul><p>In addition, each <code>OpView</code> inherits a <code>build_generic</code> method which allows
construction via a (nested in the case of variadic) sequence of <code>results</code> and
<code>operands</code>. This can be used to get some default construction semantics for
operations that are otherwise unsupported in Python, at the expense of having
a very generic signature.</p><h4 id=extending-generated-op-classes>Extending Generated Op Classes&nbsp;<a class=headline-hash href=#extending-generated-op-classes>¶</a></h4><p>Note that this is a rather complex mechanism and this section errs on the side
of explicitness. Users are encouraged to find an example and duplicate it if
they don&rsquo;t feel the need to understand the subtlety. The <code>builtin</code> dialect
provides some relatively simple examples.</p><p>As mentioned above, the build system generates Python sources like
<code>_{DIALECT_NAMESPACE}_ops_gen.py</code> for each dialect with Python bindings. It
is often desirable to to use these generated classes as a starting point for
further customization, so an extension mechanism is provided to make this
easy (you are always free to do ad-hoc patching in your <code>{DIALECT_NAMESPACE}.py</code>
file but we prefer a more standard mechanism that is applied uniformly).</p><p>To provide extensions, add a <code>_{DIALECT_NAMESPACE}_ops_ext.py</code> file to the
<code>dialects</code> module (i.e. adjacent to your <code>{DIALECT_NAMESPACE}.py</code> top-level
and the <code>*_ops_gen.py</code> file). Using the <code>builtin</code> dialect and <code>FuncOp</code> as an
example, the generated code will include an import like this:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=k>try</span><span class=p>:</span>
  <span class=kn>from</span> <span class=nn>.</span> <span class=kn>import</span> <span class=n>_builtin_ops_ext</span> <span class=k>as</span> <span class=n>_ods_ext_module</span>
<span class=k>except</span> <span class=ne>ImportError</span><span class=p>:</span>
  <span class=n>_ods_ext_module</span> <span class=o>=</span> <span class=bp>None</span>
</code></pre></div><p>Then for each generated concrete <code>OpView</code> subclass, it will apply a decorator
like:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=nd>@_ods_cext.register_operation</span><span class=p>(</span><span class=n>_Dialect</span><span class=p>)</span>
<span class=nd>@_ods_extend_opview_class</span><span class=p>(</span><span class=n>_ods_ext_module</span><span class=p>)</span>
<span class=k>class</span> <span class=nc>FuncOp</span><span class=p>(</span><span class=n>_ods_ir</span><span class=o>.</span><span class=n>OpView</span><span class=p>):</span>
</code></pre></div><p>See the <code>_ods_common.py</code> <code>extend_opview_class</code> function for details of the
mechanism. At a high level:</p><ul><li>If the extension module exists, locate an extension class for the op (in
this example, <code>FuncOp</code>):<ul><li>First by looking for an attribute with the exact name in the extension
module.</li><li>Falling back to calling a <code>select_opview_mixin(parent_opview_cls)</code>
function defined in the extension module.</li></ul></li><li>If a mixin class is found, a new subclass is dynamically created that multiply
inherits from <code>({_builtin_ops_ext.FuncOp}, _builtin_ops_gen.FuncOp)</code>.</li></ul><p>The mixin class should not inherit from anything (i.e. directly extends
<code>object</code> only). The facility is typically used to define custom <code>__init__</code>
methods, properties, instance methods and static methods. Due to the
inheritance ordering, the mixin class can act as though it extends the
generated <code>OpView</code> subclass in most contexts (i.e.
<code>issubclass(_builtin_ops_ext.FuncOp, OpView)</code> will return <code>False</code> but usage
generally allows you treat it as duck typed as an <code>OpView</code>).</p><p>There are a couple of recommendations, given how the class hierarchy is
defined:</p><ul><li>For static methods that need to instantiate the actual &ldquo;leaf&rdquo; op (which
is dynamically generated and would result in circular dependencies to try
to reference by name), prefer to use <code>@classmethod</code> and the concrete
subclass will be provided as your first <code>cls</code> argument. See
<code>_builtin_ops_ext.FuncOp.from_py_func</code> as an example.</li><li>If seeking to replace the generated <code>__init__</code> method entirely, you may
actually want to invoke the super-super-class <code>mlir.ir.OpView</code> constructor
directly, as it takes an <code>mlir.ir.Operation</code>, which is likely what you
are constructing (i.e. the generated <code>__init__</code> method likely adds more
API constraints than you want to expose in a custom builder).</li></ul><p>A pattern that comes up frequently is wanting to provide a sugared <code>__init__</code>
method which has optional or type-polymorphism/implicit conversions but to
otherwise want to invoke the default op building logic. For such cases,
it is recommended to use an idiom such as:</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python>  <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>sugar</span><span class=p>,</span> <span class=n>spice</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=bp>None</span><span class=p>,</span> <span class=n>ip</span><span class=o>=</span><span class=bp>None</span><span class=p>):</span>
    <span class=o>...</span> <span class=n>massage</span> <span class=n>into</span> <span class=n>result_type</span><span class=p>,</span> <span class=n>operands</span><span class=p>,</span> <span class=n>attributes</span> <span class=o>...</span>
    <span class=n>OpView</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>build_generic</span><span class=p>(</span>
        <span class=n>results</span><span class=o>=</span><span class=p>[</span><span class=n>result_type</span><span class=p>],</span>
        <span class=n>operands</span><span class=o>=</span><span class=n>operands</span><span class=p>,</span>
        <span class=n>attributes</span><span class=o>=</span><span class=n>attributes</span><span class=p>,</span>
        <span class=n>loc</span><span class=o>=</span><span class=n>loc</span><span class=p>,</span>
        <span class=n>ip</span><span class=o>=</span><span class=n>ip</span><span class=p>))</span>
</code></pre></div><p>Refer to the documentation for <code>build_generic</code> for more information.</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Bindings/ title=Bindings><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Bindings</a>
<a class="nav nav-next" href=/docs/Tools/ title=Tools>Next - Tools <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class="parent has-sub-menu"><a href=/docs/Bindings/>Bindings<span class="mark opened">-</span></a><ul class=sub-menu><li class=active><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tools/LinalgOpDsl/>linalg_opdsl tool</a></li><li><a href=/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li></ul></li><li><a href=/docs/MemRefPasses/></a></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/BufferDeallocationInternals/>Buffer Deallocation - Internals</a></li><li><a href=/docs/Bufferization/>Bufferization</a></li><li><a href=/docs/LLVMDialectMemRefConvention/>Built-in Function and MemRef Calling Convention</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/DataLayout/>Data Layout Modeling</a></li><li><a href=/docs/DebugActions/>Debug Actions</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/DLTIDialect/></a></li><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=/docs/Dialects/Linalg/>'linalg' Dialect</a></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/Standard/>'std' Dialect</a></li><li><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li></ul></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/DefiningAttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>